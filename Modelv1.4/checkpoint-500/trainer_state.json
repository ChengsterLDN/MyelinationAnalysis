{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.49603174603174605,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00992063492063492,
      "grad_norm": 1.3719464540481567,
      "learning_rate": 4.985119047619048e-05,
      "loss": 0.9941,
      "step": 10
    },
    {
      "epoch": 0.01984126984126984,
      "grad_norm": 1.2379059791564941,
      "learning_rate": 4.968584656084656e-05,
      "loss": 0.6145,
      "step": 20
    },
    {
      "epoch": 0.02976190476190476,
      "grad_norm": 1.8104429244995117,
      "learning_rate": 4.952050264550265e-05,
      "loss": 0.4881,
      "step": 30
    },
    {
      "epoch": 0.03968253968253968,
      "grad_norm": 1.202915072441101,
      "learning_rate": 4.9355158730158735e-05,
      "loss": 0.4633,
      "step": 40
    },
    {
      "epoch": 0.0496031746031746,
      "grad_norm": 3.3433964252471924,
      "learning_rate": 4.9189814814814815e-05,
      "loss": 0.3231,
      "step": 50
    },
    {
      "epoch": 0.05952380952380952,
      "grad_norm": 0.9038017392158508,
      "learning_rate": 4.90244708994709e-05,
      "loss": 0.3268,
      "step": 60
    },
    {
      "epoch": 0.06944444444444445,
      "grad_norm": 2.038198947906494,
      "learning_rate": 4.8859126984126984e-05,
      "loss": 0.2575,
      "step": 70
    },
    {
      "epoch": 0.07936507936507936,
      "grad_norm": 2.7609469890594482,
      "learning_rate": 4.869378306878307e-05,
      "loss": 0.2613,
      "step": 80
    },
    {
      "epoch": 0.08928571428571429,
      "grad_norm": 3.6198573112487793,
      "learning_rate": 4.852843915343915e-05,
      "loss": 0.3895,
      "step": 90
    },
    {
      "epoch": 0.0992063492063492,
      "grad_norm": 0.7911335229873657,
      "learning_rate": 4.836309523809524e-05,
      "loss": 0.2519,
      "step": 100
    },
    {
      "epoch": 0.10912698412698413,
      "grad_norm": 0.7651588916778564,
      "learning_rate": 4.819775132275133e-05,
      "loss": 0.2423,
      "step": 110
    },
    {
      "epoch": 0.11904761904761904,
      "grad_norm": 0.8101857900619507,
      "learning_rate": 4.803240740740741e-05,
      "loss": 0.3194,
      "step": 120
    },
    {
      "epoch": 0.12896825396825398,
      "grad_norm": 1.2528316974639893,
      "learning_rate": 4.7867063492063496e-05,
      "loss": 0.2383,
      "step": 130
    },
    {
      "epoch": 0.1388888888888889,
      "grad_norm": 0.9945611357688904,
      "learning_rate": 4.7701719576719577e-05,
      "loss": 0.3078,
      "step": 140
    },
    {
      "epoch": 0.1488095238095238,
      "grad_norm": 2.178577184677124,
      "learning_rate": 4.7536375661375664e-05,
      "loss": 0.2212,
      "step": 150
    },
    {
      "epoch": 0.15873015873015872,
      "grad_norm": 1.6458840370178223,
      "learning_rate": 4.7371031746031745e-05,
      "loss": 0.2925,
      "step": 160
    },
    {
      "epoch": 0.16865079365079366,
      "grad_norm": 0.43491241335868835,
      "learning_rate": 4.720568783068783e-05,
      "loss": 0.3086,
      "step": 170
    },
    {
      "epoch": 0.17857142857142858,
      "grad_norm": 4.1074323654174805,
      "learning_rate": 4.704034391534391e-05,
      "loss": 0.2965,
      "step": 180
    },
    {
      "epoch": 0.1884920634920635,
      "grad_norm": 2.8642311096191406,
      "learning_rate": 4.6875e-05,
      "loss": 0.2723,
      "step": 190
    },
    {
      "epoch": 0.1984126984126984,
      "grad_norm": 3.72428035736084,
      "learning_rate": 4.670965608465609e-05,
      "loss": 0.288,
      "step": 200
    },
    {
      "epoch": 0.20833333333333334,
      "grad_norm": 1.5513815879821777,
      "learning_rate": 4.654431216931217e-05,
      "loss": 0.1966,
      "step": 210
    },
    {
      "epoch": 0.21825396825396826,
      "grad_norm": 1.6815180778503418,
      "learning_rate": 4.637896825396826e-05,
      "loss": 0.2001,
      "step": 220
    },
    {
      "epoch": 0.22817460317460317,
      "grad_norm": 1.9883300065994263,
      "learning_rate": 4.621362433862434e-05,
      "loss": 0.3088,
      "step": 230
    },
    {
      "epoch": 0.23809523809523808,
      "grad_norm": 1.7422568798065186,
      "learning_rate": 4.6048280423280425e-05,
      "loss": 0.1754,
      "step": 240
    },
    {
      "epoch": 0.24801587301587302,
      "grad_norm": 5.885217189788818,
      "learning_rate": 4.5882936507936506e-05,
      "loss": 0.2632,
      "step": 250
    },
    {
      "epoch": 0.25793650793650796,
      "grad_norm": 3.6565613746643066,
      "learning_rate": 4.5717592592592594e-05,
      "loss": 0.2004,
      "step": 260
    },
    {
      "epoch": 0.26785714285714285,
      "grad_norm": 0.864947497844696,
      "learning_rate": 4.5552248677248675e-05,
      "loss": 0.1733,
      "step": 270
    },
    {
      "epoch": 0.2777777777777778,
      "grad_norm": 0.4264894723892212,
      "learning_rate": 4.538690476190476e-05,
      "loss": 0.2012,
      "step": 280
    },
    {
      "epoch": 0.2876984126984127,
      "grad_norm": 3.0318942070007324,
      "learning_rate": 4.522156084656085e-05,
      "loss": 0.2405,
      "step": 290
    },
    {
      "epoch": 0.2976190476190476,
      "grad_norm": 2.015702962875366,
      "learning_rate": 4.505621693121693e-05,
      "loss": 0.2608,
      "step": 300
    },
    {
      "epoch": 0.30753968253968256,
      "grad_norm": 2.5453720092773438,
      "learning_rate": 4.489087301587302e-05,
      "loss": 0.1919,
      "step": 310
    },
    {
      "epoch": 0.31746031746031744,
      "grad_norm": 2.011779546737671,
      "learning_rate": 4.47255291005291e-05,
      "loss": 0.158,
      "step": 320
    },
    {
      "epoch": 0.3273809523809524,
      "grad_norm": 3.1051385402679443,
      "learning_rate": 4.456018518518519e-05,
      "loss": 0.2216,
      "step": 330
    },
    {
      "epoch": 0.3373015873015873,
      "grad_norm": 1.918552041053772,
      "learning_rate": 4.439484126984127e-05,
      "loss": 0.1994,
      "step": 340
    },
    {
      "epoch": 0.3472222222222222,
      "grad_norm": 0.5273995995521545,
      "learning_rate": 4.4229497354497355e-05,
      "loss": 0.122,
      "step": 350
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 0.6884121894836426,
      "learning_rate": 4.406415343915344e-05,
      "loss": 0.184,
      "step": 360
    },
    {
      "epoch": 0.36706349206349204,
      "grad_norm": 2.3656935691833496,
      "learning_rate": 4.3898809523809523e-05,
      "loss": 0.2297,
      "step": 370
    },
    {
      "epoch": 0.376984126984127,
      "grad_norm": 2.9331512451171875,
      "learning_rate": 4.373346560846561e-05,
      "loss": 0.2267,
      "step": 380
    },
    {
      "epoch": 0.3869047619047619,
      "grad_norm": 1.8614566326141357,
      "learning_rate": 4.356812169312169e-05,
      "loss": 0.1711,
      "step": 390
    },
    {
      "epoch": 0.3968253968253968,
      "grad_norm": 1.0340700149536133,
      "learning_rate": 4.340277777777778e-05,
      "loss": 0.1456,
      "step": 400
    },
    {
      "epoch": 0.40674603174603174,
      "grad_norm": 0.6053463220596313,
      "learning_rate": 4.323743386243386e-05,
      "loss": 0.1799,
      "step": 410
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 1.6186718940734863,
      "learning_rate": 4.307208994708995e-05,
      "loss": 0.1781,
      "step": 420
    },
    {
      "epoch": 0.42658730158730157,
      "grad_norm": 2.79207706451416,
      "learning_rate": 4.290674603174603e-05,
      "loss": 0.2176,
      "step": 430
    },
    {
      "epoch": 0.4365079365079365,
      "grad_norm": 0.8014230728149414,
      "learning_rate": 4.2741402116402116e-05,
      "loss": 0.1968,
      "step": 440
    },
    {
      "epoch": 0.44642857142857145,
      "grad_norm": 2.2437567710876465,
      "learning_rate": 4.2576058201058204e-05,
      "loss": 0.2028,
      "step": 450
    },
    {
      "epoch": 0.45634920634920634,
      "grad_norm": 3.0505282878875732,
      "learning_rate": 4.2410714285714285e-05,
      "loss": 0.2338,
      "step": 460
    },
    {
      "epoch": 0.4662698412698413,
      "grad_norm": 1.1223489046096802,
      "learning_rate": 4.224537037037037e-05,
      "loss": 0.1366,
      "step": 470
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 4.450564861297607,
      "learning_rate": 4.208002645502645e-05,
      "loss": 0.1737,
      "step": 480
    },
    {
      "epoch": 0.4861111111111111,
      "grad_norm": 0.6995857954025269,
      "learning_rate": 4.191468253968254e-05,
      "loss": 0.1493,
      "step": 490
    },
    {
      "epoch": 0.49603174603174605,
      "grad_norm": 0.6147041320800781,
      "learning_rate": 4.174933862433862e-05,
      "loss": 0.1263,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 3024,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.19947029495808e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
