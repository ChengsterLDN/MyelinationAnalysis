{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3033,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04945598417408507,
      "grad_norm": 2.9174346923828125,
      "learning_rate": 4.9192218925156614e-05,
      "loss": 0.3308,
      "step": 50
    },
    {
      "epoch": 0.09891196834817013,
      "grad_norm": 3.7626681327819824,
      "learning_rate": 4.8367952522255196e-05,
      "loss": 0.2649,
      "step": 100
    },
    {
      "epoch": 0.14836795252225518,
      "grad_norm": 0.036618925631046295,
      "learning_rate": 4.754368611935378e-05,
      "loss": 0.203,
      "step": 150
    },
    {
      "epoch": 0.19782393669634027,
      "grad_norm": 0.2765052318572998,
      "learning_rate": 4.671941971645236e-05,
      "loss": 0.2279,
      "step": 200
    },
    {
      "epoch": 0.24727992087042533,
      "grad_norm": 5.448812007904053,
      "learning_rate": 4.589515331355094e-05,
      "loss": 0.219,
      "step": 250
    },
    {
      "epoch": 0.29673590504451036,
      "grad_norm": 0.13061441481113434,
      "learning_rate": 4.5070886910649524e-05,
      "loss": 0.1813,
      "step": 300
    },
    {
      "epoch": 0.34619188921859545,
      "grad_norm": 1.5132185220718384,
      "learning_rate": 4.4246620507748105e-05,
      "loss": 0.1966,
      "step": 350
    },
    {
      "epoch": 0.39564787339268054,
      "grad_norm": 0.41396087408065796,
      "learning_rate": 4.3422354104846694e-05,
      "loss": 0.1808,
      "step": 400
    },
    {
      "epoch": 0.44510385756676557,
      "grad_norm": 4.272385120391846,
      "learning_rate": 4.259808770194527e-05,
      "loss": 0.2183,
      "step": 450
    },
    {
      "epoch": 0.49455984174085066,
      "grad_norm": 0.18913082778453827,
      "learning_rate": 4.177382129904385e-05,
      "loss": 0.1646,
      "step": 500
    },
    {
      "epoch": 0.5440158259149357,
      "grad_norm": 4.672284126281738,
      "learning_rate": 4.094955489614243e-05,
      "loss": 0.145,
      "step": 550
    },
    {
      "epoch": 0.5934718100890207,
      "grad_norm": 5.994455337524414,
      "learning_rate": 4.012528849324102e-05,
      "loss": 0.1302,
      "step": 600
    },
    {
      "epoch": 0.6429277942631059,
      "grad_norm": 0.07549354434013367,
      "learning_rate": 3.93010220903396e-05,
      "loss": 0.1215,
      "step": 650
    },
    {
      "epoch": 0.6923837784371909,
      "grad_norm": 0.1852351427078247,
      "learning_rate": 3.8476755687438185e-05,
      "loss": 0.1499,
      "step": 700
    },
    {
      "epoch": 0.7418397626112759,
      "grad_norm": 1.3884121179580688,
      "learning_rate": 3.765248928453676e-05,
      "loss": 0.1276,
      "step": 750
    },
    {
      "epoch": 0.7912957467853611,
      "grad_norm": 2.3600270748138428,
      "learning_rate": 3.682822288163534e-05,
      "loss": 0.1276,
      "step": 800
    },
    {
      "epoch": 0.8407517309594461,
      "grad_norm": 9.456711769104004,
      "learning_rate": 3.600395647873393e-05,
      "loss": 0.1253,
      "step": 850
    },
    {
      "epoch": 0.8902077151335311,
      "grad_norm": 0.0861482098698616,
      "learning_rate": 3.517969007583251e-05,
      "loss": 0.1249,
      "step": 900
    },
    {
      "epoch": 0.9396636993076162,
      "grad_norm": 0.240980327129364,
      "learning_rate": 3.4355423672931094e-05,
      "loss": 0.1439,
      "step": 950
    },
    {
      "epoch": 0.9891196834817013,
      "grad_norm": 4.580379486083984,
      "learning_rate": 3.3531157270029676e-05,
      "loss": 0.0859,
      "step": 1000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9302777777777778,
      "eval_loss": 0.2056514471769333,
      "eval_runtime": 333.2985,
      "eval_samples_per_second": 10.801,
      "eval_steps_per_second": 1.35,
      "step": 1011
    },
    {
      "epoch": 1.0385756676557865,
      "grad_norm": 11.65742301940918,
      "learning_rate": 3.270689086712826e-05,
      "loss": 0.0607,
      "step": 1050
    },
    {
      "epoch": 1.0880316518298714,
      "grad_norm": 4.67764949798584,
      "learning_rate": 3.188262446422684e-05,
      "loss": 0.0869,
      "step": 1100
    },
    {
      "epoch": 1.1374876360039565,
      "grad_norm": 4.223126411437988,
      "learning_rate": 3.105835806132542e-05,
      "loss": 0.0596,
      "step": 1150
    },
    {
      "epoch": 1.1869436201780414,
      "grad_norm": 1.4673439264297485,
      "learning_rate": 3.0234091658424003e-05,
      "loss": 0.0597,
      "step": 1200
    },
    {
      "epoch": 1.2363996043521266,
      "grad_norm": 2.450866937637329,
      "learning_rate": 2.940982525552259e-05,
      "loss": 0.0657,
      "step": 1250
    },
    {
      "epoch": 1.2858555885262117,
      "grad_norm": 1.1131072044372559,
      "learning_rate": 2.858555885262117e-05,
      "loss": 0.0664,
      "step": 1300
    },
    {
      "epoch": 1.3353115727002967,
      "grad_norm": 0.23759667575359344,
      "learning_rate": 2.776129244971975e-05,
      "loss": 0.0604,
      "step": 1350
    },
    {
      "epoch": 1.3847675568743818,
      "grad_norm": 2.8538880348205566,
      "learning_rate": 2.693702604681833e-05,
      "loss": 0.0372,
      "step": 1400
    },
    {
      "epoch": 1.434223541048467,
      "grad_norm": 0.2326451539993286,
      "learning_rate": 2.6112759643916916e-05,
      "loss": 0.0408,
      "step": 1450
    },
    {
      "epoch": 1.4836795252225519,
      "grad_norm": 0.016099831089377403,
      "learning_rate": 2.5288493241015498e-05,
      "loss": 0.0229,
      "step": 1500
    },
    {
      "epoch": 1.533135509396637,
      "grad_norm": 14.414401054382324,
      "learning_rate": 2.446422683811408e-05,
      "loss": 0.0608,
      "step": 1550
    },
    {
      "epoch": 1.582591493570722,
      "grad_norm": 13.000870704650879,
      "learning_rate": 2.363996043521266e-05,
      "loss": 0.0561,
      "step": 1600
    },
    {
      "epoch": 1.632047477744807,
      "grad_norm": 0.009800653904676437,
      "learning_rate": 2.2815694032311243e-05,
      "loss": 0.0473,
      "step": 1650
    },
    {
      "epoch": 1.6815034619188922,
      "grad_norm": 0.0076597402803599834,
      "learning_rate": 2.199142762940983e-05,
      "loss": 0.0266,
      "step": 1700
    },
    {
      "epoch": 1.7309594460929771,
      "grad_norm": 8.919785499572754,
      "learning_rate": 2.1167161226508407e-05,
      "loss": 0.0563,
      "step": 1750
    },
    {
      "epoch": 1.7804154302670623,
      "grad_norm": 0.008616923354566097,
      "learning_rate": 2.034289482360699e-05,
      "loss": 0.0202,
      "step": 1800
    },
    {
      "epoch": 1.8298714144411474,
      "grad_norm": 6.392031669616699,
      "learning_rate": 1.9518628420705574e-05,
      "loss": 0.0265,
      "step": 1850
    },
    {
      "epoch": 1.8793273986152323,
      "grad_norm": 0.021961361169815063,
      "learning_rate": 1.8694362017804153e-05,
      "loss": 0.0143,
      "step": 1900
    },
    {
      "epoch": 1.9287833827893175,
      "grad_norm": 0.22963128983974457,
      "learning_rate": 1.7870095614902738e-05,
      "loss": 0.0126,
      "step": 1950
    },
    {
      "epoch": 1.9782393669634026,
      "grad_norm": 0.03205195069313049,
      "learning_rate": 1.704582921200132e-05,
      "loss": 0.0176,
      "step": 2000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9433333333333334,
      "eval_loss": 0.24037261307239532,
      "eval_runtime": 384.4336,
      "eval_samples_per_second": 9.364,
      "eval_steps_per_second": 1.171,
      "step": 2022
    },
    {
      "epoch": 2.0276953511374876,
      "grad_norm": 0.037723835557699203,
      "learning_rate": 1.62215628090999e-05,
      "loss": 0.0181,
      "step": 2050
    },
    {
      "epoch": 2.077151335311573,
      "grad_norm": 0.015164133161306381,
      "learning_rate": 1.5397296406198483e-05,
      "loss": 0.0061,
      "step": 2100
    },
    {
      "epoch": 2.126607319485658,
      "grad_norm": 1.5975239276885986,
      "learning_rate": 1.4573030003297067e-05,
      "loss": 0.0031,
      "step": 2150
    },
    {
      "epoch": 2.1760633036597428,
      "grad_norm": 0.01510209497064352,
      "learning_rate": 1.3748763600395647e-05,
      "loss": 0.0019,
      "step": 2200
    },
    {
      "epoch": 2.2255192878338277,
      "grad_norm": 0.004530236590653658,
      "learning_rate": 1.292449719749423e-05,
      "loss": 0.0024,
      "step": 2250
    },
    {
      "epoch": 2.274975272007913,
      "grad_norm": 0.015008741058409214,
      "learning_rate": 1.2100230794592814e-05,
      "loss": 0.0072,
      "step": 2300
    },
    {
      "epoch": 2.324431256181998,
      "grad_norm": 0.2835650146007538,
      "learning_rate": 1.1275964391691394e-05,
      "loss": 0.0018,
      "step": 2350
    },
    {
      "epoch": 2.373887240356083,
      "grad_norm": 0.01241409033536911,
      "learning_rate": 1.0451697988789976e-05,
      "loss": 0.002,
      "step": 2400
    },
    {
      "epoch": 2.4233432245301683,
      "grad_norm": 0.08189073950052261,
      "learning_rate": 9.62743158588856e-06,
      "loss": 0.0025,
      "step": 2450
    },
    {
      "epoch": 2.472799208704253,
      "grad_norm": 0.02157917618751526,
      "learning_rate": 8.803165182987141e-06,
      "loss": 0.0014,
      "step": 2500
    },
    {
      "epoch": 2.5222551928783385,
      "grad_norm": 0.004065781831741333,
      "learning_rate": 7.978898780085723e-06,
      "loss": 0.0031,
      "step": 2550
    },
    {
      "epoch": 2.5717111770524235,
      "grad_norm": 0.07673630863428116,
      "learning_rate": 7.154632377184306e-06,
      "loss": 0.0023,
      "step": 2600
    },
    {
      "epoch": 2.6211671612265084,
      "grad_norm": 0.005471100099384785,
      "learning_rate": 6.330365974282889e-06,
      "loss": 0.0018,
      "step": 2650
    },
    {
      "epoch": 2.6706231454005933,
      "grad_norm": 0.013139192946255207,
      "learning_rate": 5.5060995713814705e-06,
      "loss": 0.002,
      "step": 2700
    },
    {
      "epoch": 2.7200791295746787,
      "grad_norm": 0.0507836677134037,
      "learning_rate": 4.681833168480053e-06,
      "loss": 0.0015,
      "step": 2750
    },
    {
      "epoch": 2.7695351137487636,
      "grad_norm": 0.008723187260329723,
      "learning_rate": 3.857566765578635e-06,
      "loss": 0.0013,
      "step": 2800
    },
    {
      "epoch": 2.8189910979228485,
      "grad_norm": 0.013229204341769218,
      "learning_rate": 3.0333003626772173e-06,
      "loss": 0.0012,
      "step": 2850
    },
    {
      "epoch": 2.868447082096934,
      "grad_norm": 0.017097074538469315,
      "learning_rate": 2.2090339597757996e-06,
      "loss": 0.0014,
      "step": 2900
    },
    {
      "epoch": 2.917903066271019,
      "grad_norm": 0.014343888498842716,
      "learning_rate": 1.3847675568743818e-06,
      "loss": 0.0014,
      "step": 2950
    },
    {
      "epoch": 2.9673590504451037,
      "grad_norm": 0.012162506580352783,
      "learning_rate": 5.605011539729641e-07,
      "loss": 0.0017,
      "step": 3000
    }
  ],
  "logging_steps": 50,
  "max_steps": 3033,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.7605986809215713e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
