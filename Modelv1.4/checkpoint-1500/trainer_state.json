{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.4880952380952381,
  "eval_steps": 500,
  "global_step": 1500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00992063492063492,
      "grad_norm": 1.3719464540481567,
      "learning_rate": 4.985119047619048e-05,
      "loss": 0.9941,
      "step": 10
    },
    {
      "epoch": 0.01984126984126984,
      "grad_norm": 1.2379059791564941,
      "learning_rate": 4.968584656084656e-05,
      "loss": 0.6145,
      "step": 20
    },
    {
      "epoch": 0.02976190476190476,
      "grad_norm": 1.8104429244995117,
      "learning_rate": 4.952050264550265e-05,
      "loss": 0.4881,
      "step": 30
    },
    {
      "epoch": 0.03968253968253968,
      "grad_norm": 1.202915072441101,
      "learning_rate": 4.9355158730158735e-05,
      "loss": 0.4633,
      "step": 40
    },
    {
      "epoch": 0.0496031746031746,
      "grad_norm": 3.3433964252471924,
      "learning_rate": 4.9189814814814815e-05,
      "loss": 0.3231,
      "step": 50
    },
    {
      "epoch": 0.05952380952380952,
      "grad_norm": 0.9038017392158508,
      "learning_rate": 4.90244708994709e-05,
      "loss": 0.3268,
      "step": 60
    },
    {
      "epoch": 0.06944444444444445,
      "grad_norm": 2.038198947906494,
      "learning_rate": 4.8859126984126984e-05,
      "loss": 0.2575,
      "step": 70
    },
    {
      "epoch": 0.07936507936507936,
      "grad_norm": 2.7609469890594482,
      "learning_rate": 4.869378306878307e-05,
      "loss": 0.2613,
      "step": 80
    },
    {
      "epoch": 0.08928571428571429,
      "grad_norm": 3.6198573112487793,
      "learning_rate": 4.852843915343915e-05,
      "loss": 0.3895,
      "step": 90
    },
    {
      "epoch": 0.0992063492063492,
      "grad_norm": 0.7911335229873657,
      "learning_rate": 4.836309523809524e-05,
      "loss": 0.2519,
      "step": 100
    },
    {
      "epoch": 0.10912698412698413,
      "grad_norm": 0.7651588916778564,
      "learning_rate": 4.819775132275133e-05,
      "loss": 0.2423,
      "step": 110
    },
    {
      "epoch": 0.11904761904761904,
      "grad_norm": 0.8101857900619507,
      "learning_rate": 4.803240740740741e-05,
      "loss": 0.3194,
      "step": 120
    },
    {
      "epoch": 0.12896825396825398,
      "grad_norm": 1.2528316974639893,
      "learning_rate": 4.7867063492063496e-05,
      "loss": 0.2383,
      "step": 130
    },
    {
      "epoch": 0.1388888888888889,
      "grad_norm": 0.9945611357688904,
      "learning_rate": 4.7701719576719577e-05,
      "loss": 0.3078,
      "step": 140
    },
    {
      "epoch": 0.1488095238095238,
      "grad_norm": 2.178577184677124,
      "learning_rate": 4.7536375661375664e-05,
      "loss": 0.2212,
      "step": 150
    },
    {
      "epoch": 0.15873015873015872,
      "grad_norm": 1.6458840370178223,
      "learning_rate": 4.7371031746031745e-05,
      "loss": 0.2925,
      "step": 160
    },
    {
      "epoch": 0.16865079365079366,
      "grad_norm": 0.43491241335868835,
      "learning_rate": 4.720568783068783e-05,
      "loss": 0.3086,
      "step": 170
    },
    {
      "epoch": 0.17857142857142858,
      "grad_norm": 4.1074323654174805,
      "learning_rate": 4.704034391534391e-05,
      "loss": 0.2965,
      "step": 180
    },
    {
      "epoch": 0.1884920634920635,
      "grad_norm": 2.8642311096191406,
      "learning_rate": 4.6875e-05,
      "loss": 0.2723,
      "step": 190
    },
    {
      "epoch": 0.1984126984126984,
      "grad_norm": 3.72428035736084,
      "learning_rate": 4.670965608465609e-05,
      "loss": 0.288,
      "step": 200
    },
    {
      "epoch": 0.20833333333333334,
      "grad_norm": 1.5513815879821777,
      "learning_rate": 4.654431216931217e-05,
      "loss": 0.1966,
      "step": 210
    },
    {
      "epoch": 0.21825396825396826,
      "grad_norm": 1.6815180778503418,
      "learning_rate": 4.637896825396826e-05,
      "loss": 0.2001,
      "step": 220
    },
    {
      "epoch": 0.22817460317460317,
      "grad_norm": 1.9883300065994263,
      "learning_rate": 4.621362433862434e-05,
      "loss": 0.3088,
      "step": 230
    },
    {
      "epoch": 0.23809523809523808,
      "grad_norm": 1.7422568798065186,
      "learning_rate": 4.6048280423280425e-05,
      "loss": 0.1754,
      "step": 240
    },
    {
      "epoch": 0.24801587301587302,
      "grad_norm": 5.885217189788818,
      "learning_rate": 4.5882936507936506e-05,
      "loss": 0.2632,
      "step": 250
    },
    {
      "epoch": 0.25793650793650796,
      "grad_norm": 3.6565613746643066,
      "learning_rate": 4.5717592592592594e-05,
      "loss": 0.2004,
      "step": 260
    },
    {
      "epoch": 0.26785714285714285,
      "grad_norm": 0.864947497844696,
      "learning_rate": 4.5552248677248675e-05,
      "loss": 0.1733,
      "step": 270
    },
    {
      "epoch": 0.2777777777777778,
      "grad_norm": 0.4264894723892212,
      "learning_rate": 4.538690476190476e-05,
      "loss": 0.2012,
      "step": 280
    },
    {
      "epoch": 0.2876984126984127,
      "grad_norm": 3.0318942070007324,
      "learning_rate": 4.522156084656085e-05,
      "loss": 0.2405,
      "step": 290
    },
    {
      "epoch": 0.2976190476190476,
      "grad_norm": 2.015702962875366,
      "learning_rate": 4.505621693121693e-05,
      "loss": 0.2608,
      "step": 300
    },
    {
      "epoch": 0.30753968253968256,
      "grad_norm": 2.5453720092773438,
      "learning_rate": 4.489087301587302e-05,
      "loss": 0.1919,
      "step": 310
    },
    {
      "epoch": 0.31746031746031744,
      "grad_norm": 2.011779546737671,
      "learning_rate": 4.47255291005291e-05,
      "loss": 0.158,
      "step": 320
    },
    {
      "epoch": 0.3273809523809524,
      "grad_norm": 3.1051385402679443,
      "learning_rate": 4.456018518518519e-05,
      "loss": 0.2216,
      "step": 330
    },
    {
      "epoch": 0.3373015873015873,
      "grad_norm": 1.918552041053772,
      "learning_rate": 4.439484126984127e-05,
      "loss": 0.1994,
      "step": 340
    },
    {
      "epoch": 0.3472222222222222,
      "grad_norm": 0.5273995995521545,
      "learning_rate": 4.4229497354497355e-05,
      "loss": 0.122,
      "step": 350
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 0.6884121894836426,
      "learning_rate": 4.406415343915344e-05,
      "loss": 0.184,
      "step": 360
    },
    {
      "epoch": 0.36706349206349204,
      "grad_norm": 2.3656935691833496,
      "learning_rate": 4.3898809523809523e-05,
      "loss": 0.2297,
      "step": 370
    },
    {
      "epoch": 0.376984126984127,
      "grad_norm": 2.9331512451171875,
      "learning_rate": 4.373346560846561e-05,
      "loss": 0.2267,
      "step": 380
    },
    {
      "epoch": 0.3869047619047619,
      "grad_norm": 1.8614566326141357,
      "learning_rate": 4.356812169312169e-05,
      "loss": 0.1711,
      "step": 390
    },
    {
      "epoch": 0.3968253968253968,
      "grad_norm": 1.0340700149536133,
      "learning_rate": 4.340277777777778e-05,
      "loss": 0.1456,
      "step": 400
    },
    {
      "epoch": 0.40674603174603174,
      "grad_norm": 0.6053463220596313,
      "learning_rate": 4.323743386243386e-05,
      "loss": 0.1799,
      "step": 410
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 1.6186718940734863,
      "learning_rate": 4.307208994708995e-05,
      "loss": 0.1781,
      "step": 420
    },
    {
      "epoch": 0.42658730158730157,
      "grad_norm": 2.79207706451416,
      "learning_rate": 4.290674603174603e-05,
      "loss": 0.2176,
      "step": 430
    },
    {
      "epoch": 0.4365079365079365,
      "grad_norm": 0.8014230728149414,
      "learning_rate": 4.2741402116402116e-05,
      "loss": 0.1968,
      "step": 440
    },
    {
      "epoch": 0.44642857142857145,
      "grad_norm": 2.2437567710876465,
      "learning_rate": 4.2576058201058204e-05,
      "loss": 0.2028,
      "step": 450
    },
    {
      "epoch": 0.45634920634920634,
      "grad_norm": 3.0505282878875732,
      "learning_rate": 4.2410714285714285e-05,
      "loss": 0.2338,
      "step": 460
    },
    {
      "epoch": 0.4662698412698413,
      "grad_norm": 1.1223489046096802,
      "learning_rate": 4.224537037037037e-05,
      "loss": 0.1366,
      "step": 470
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 4.450564861297607,
      "learning_rate": 4.208002645502645e-05,
      "loss": 0.1737,
      "step": 480
    },
    {
      "epoch": 0.4861111111111111,
      "grad_norm": 0.6995857954025269,
      "learning_rate": 4.191468253968254e-05,
      "loss": 0.1493,
      "step": 490
    },
    {
      "epoch": 0.49603174603174605,
      "grad_norm": 0.6147041320800781,
      "learning_rate": 4.174933862433862e-05,
      "loss": 0.1263,
      "step": 500
    },
    {
      "epoch": 0.5059523809523809,
      "grad_norm": 0.8544953465461731,
      "learning_rate": 4.158399470899471e-05,
      "loss": 0.1712,
      "step": 510
    },
    {
      "epoch": 0.5158730158730159,
      "grad_norm": 0.9247413873672485,
      "learning_rate": 4.14186507936508e-05,
      "loss": 0.144,
      "step": 520
    },
    {
      "epoch": 0.5257936507936508,
      "grad_norm": 2.4032070636749268,
      "learning_rate": 4.125330687830688e-05,
      "loss": 0.1912,
      "step": 530
    },
    {
      "epoch": 0.5357142857142857,
      "grad_norm": 2.98814058303833,
      "learning_rate": 4.1087962962962965e-05,
      "loss": 0.199,
      "step": 540
    },
    {
      "epoch": 0.5456349206349206,
      "grad_norm": 0.9423033595085144,
      "learning_rate": 4.0922619047619046e-05,
      "loss": 0.2026,
      "step": 550
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.5680019855499268,
      "learning_rate": 4.0757275132275133e-05,
      "loss": 0.1597,
      "step": 560
    },
    {
      "epoch": 0.5654761904761905,
      "grad_norm": 0.3485705852508545,
      "learning_rate": 4.0591931216931214e-05,
      "loss": 0.1156,
      "step": 570
    },
    {
      "epoch": 0.5753968253968254,
      "grad_norm": 2.15037202835083,
      "learning_rate": 4.04265873015873e-05,
      "loss": 0.2018,
      "step": 580
    },
    {
      "epoch": 0.5853174603174603,
      "grad_norm": 0.1341075897216797,
      "learning_rate": 4.026124338624338e-05,
      "loss": 0.0855,
      "step": 590
    },
    {
      "epoch": 0.5952380952380952,
      "grad_norm": 1.1490334272384644,
      "learning_rate": 4.009589947089947e-05,
      "loss": 0.2284,
      "step": 600
    },
    {
      "epoch": 0.6051587301587301,
      "grad_norm": 2.6367533206939697,
      "learning_rate": 3.993055555555556e-05,
      "loss": 0.1153,
      "step": 610
    },
    {
      "epoch": 0.6150793650793651,
      "grad_norm": 0.10449708253145218,
      "learning_rate": 3.976521164021164e-05,
      "loss": 0.1724,
      "step": 620
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.27132198214530945,
      "learning_rate": 3.9599867724867726e-05,
      "loss": 0.1256,
      "step": 630
    },
    {
      "epoch": 0.6349206349206349,
      "grad_norm": 0.30907630920410156,
      "learning_rate": 3.943452380952381e-05,
      "loss": 0.1851,
      "step": 640
    },
    {
      "epoch": 0.6448412698412699,
      "grad_norm": 4.131710052490234,
      "learning_rate": 3.9269179894179895e-05,
      "loss": 0.1456,
      "step": 650
    },
    {
      "epoch": 0.6547619047619048,
      "grad_norm": 2.613365650177002,
      "learning_rate": 3.9103835978835976e-05,
      "loss": 0.1707,
      "step": 660
    },
    {
      "epoch": 0.6646825396825397,
      "grad_norm": 2.1130526065826416,
      "learning_rate": 3.893849206349206e-05,
      "loss": 0.1795,
      "step": 670
    },
    {
      "epoch": 0.6746031746031746,
      "grad_norm": 1.5828524827957153,
      "learning_rate": 3.877314814814815e-05,
      "loss": 0.1297,
      "step": 680
    },
    {
      "epoch": 0.6845238095238095,
      "grad_norm": 3.466740369796753,
      "learning_rate": 3.860780423280423e-05,
      "loss": 0.1755,
      "step": 690
    },
    {
      "epoch": 0.6944444444444444,
      "grad_norm": 5.604875087738037,
      "learning_rate": 3.844246031746032e-05,
      "loss": 0.1935,
      "step": 700
    },
    {
      "epoch": 0.7043650793650794,
      "grad_norm": 2.5593626499176025,
      "learning_rate": 3.82771164021164e-05,
      "loss": 0.1192,
      "step": 710
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 3.2461647987365723,
      "learning_rate": 3.811177248677249e-05,
      "loss": 0.1875,
      "step": 720
    },
    {
      "epoch": 0.7242063492063492,
      "grad_norm": 0.4990682005882263,
      "learning_rate": 3.794642857142857e-05,
      "loss": 0.0866,
      "step": 730
    },
    {
      "epoch": 0.7341269841269841,
      "grad_norm": 0.07594171911478043,
      "learning_rate": 3.7781084656084656e-05,
      "loss": 0.0921,
      "step": 740
    },
    {
      "epoch": 0.7440476190476191,
      "grad_norm": 0.2641228139400482,
      "learning_rate": 3.7615740740740744e-05,
      "loss": 0.1771,
      "step": 750
    },
    {
      "epoch": 0.753968253968254,
      "grad_norm": 1.4916601181030273,
      "learning_rate": 3.7450396825396824e-05,
      "loss": 0.1221,
      "step": 760
    },
    {
      "epoch": 0.7638888888888888,
      "grad_norm": 0.13018600642681122,
      "learning_rate": 3.728505291005291e-05,
      "loss": 0.2582,
      "step": 770
    },
    {
      "epoch": 0.7738095238095238,
      "grad_norm": 3.3499596118927,
      "learning_rate": 3.711970899470899e-05,
      "loss": 0.1294,
      "step": 780
    },
    {
      "epoch": 0.7837301587301587,
      "grad_norm": 2.761120319366455,
      "learning_rate": 3.695436507936508e-05,
      "loss": 0.2102,
      "step": 790
    },
    {
      "epoch": 0.7936507936507936,
      "grad_norm": 5.302552223205566,
      "learning_rate": 3.678902116402117e-05,
      "loss": 0.1867,
      "step": 800
    },
    {
      "epoch": 0.8035714285714286,
      "grad_norm": 0.5618389844894409,
      "learning_rate": 3.662367724867725e-05,
      "loss": 0.1046,
      "step": 810
    },
    {
      "epoch": 0.8134920634920635,
      "grad_norm": 1.3859440088272095,
      "learning_rate": 3.6458333333333336e-05,
      "loss": 0.1232,
      "step": 820
    },
    {
      "epoch": 0.8234126984126984,
      "grad_norm": 5.243439674377441,
      "learning_rate": 3.629298941798942e-05,
      "loss": 0.2123,
      "step": 830
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 3.28774094581604,
      "learning_rate": 3.6127645502645505e-05,
      "loss": 0.1462,
      "step": 840
    },
    {
      "epoch": 0.8432539682539683,
      "grad_norm": 0.245246022939682,
      "learning_rate": 3.5962301587301586e-05,
      "loss": 0.1259,
      "step": 850
    },
    {
      "epoch": 0.8531746031746031,
      "grad_norm": 2.248469591140747,
      "learning_rate": 3.579695767195767e-05,
      "loss": 0.134,
      "step": 860
    },
    {
      "epoch": 0.8630952380952381,
      "grad_norm": 0.23854048550128937,
      "learning_rate": 3.563161375661376e-05,
      "loss": 0.148,
      "step": 870
    },
    {
      "epoch": 0.873015873015873,
      "grad_norm": 1.5220264196395874,
      "learning_rate": 3.546626984126984e-05,
      "loss": 0.108,
      "step": 880
    },
    {
      "epoch": 0.8829365079365079,
      "grad_norm": 0.084409698843956,
      "learning_rate": 3.530092592592593e-05,
      "loss": 0.1012,
      "step": 890
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 2.081437587738037,
      "learning_rate": 3.513558201058201e-05,
      "loss": 0.2269,
      "step": 900
    },
    {
      "epoch": 0.9027777777777778,
      "grad_norm": 3.7749485969543457,
      "learning_rate": 3.49702380952381e-05,
      "loss": 0.1469,
      "step": 910
    },
    {
      "epoch": 0.9126984126984127,
      "grad_norm": 2.906954765319824,
      "learning_rate": 3.4804894179894185e-05,
      "loss": 0.2006,
      "step": 920
    },
    {
      "epoch": 0.9226190476190477,
      "grad_norm": 1.0022488832473755,
      "learning_rate": 3.4639550264550266e-05,
      "loss": 0.1111,
      "step": 930
    },
    {
      "epoch": 0.9325396825396826,
      "grad_norm": 2.0710771083831787,
      "learning_rate": 3.4474206349206354e-05,
      "loss": 0.1074,
      "step": 940
    },
    {
      "epoch": 0.9424603174603174,
      "grad_norm": 0.38613054156303406,
      "learning_rate": 3.4308862433862434e-05,
      "loss": 0.1262,
      "step": 950
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 0.36195993423461914,
      "learning_rate": 3.414351851851852e-05,
      "loss": 0.1678,
      "step": 960
    },
    {
      "epoch": 0.9623015873015873,
      "grad_norm": 0.8114310503005981,
      "learning_rate": 3.397817460317461e-05,
      "loss": 0.109,
      "step": 970
    },
    {
      "epoch": 0.9722222222222222,
      "grad_norm": 3.552114963531494,
      "learning_rate": 3.381283068783069e-05,
      "loss": 0.1674,
      "step": 980
    },
    {
      "epoch": 0.9821428571428571,
      "grad_norm": 0.8657990097999573,
      "learning_rate": 3.364748677248678e-05,
      "loss": 0.1636,
      "step": 990
    },
    {
      "epoch": 0.9920634920634921,
      "grad_norm": 1.0813343524932861,
      "learning_rate": 3.348214285714286e-05,
      "loss": 0.1162,
      "step": 1000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.935,
      "eval_loss": 0.18352161347866058,
      "eval_runtime": 337.7978,
      "eval_samples_per_second": 10.657,
      "eval_steps_per_second": 1.332,
      "step": 1008
    },
    {
      "epoch": 1.001984126984127,
      "grad_norm": 2.6641106605529785,
      "learning_rate": 3.3316798941798946e-05,
      "loss": 0.111,
      "step": 1010
    },
    {
      "epoch": 1.0119047619047619,
      "grad_norm": 0.05984215438365936,
      "learning_rate": 3.315145502645503e-05,
      "loss": 0.0551,
      "step": 1020
    },
    {
      "epoch": 1.0218253968253967,
      "grad_norm": 2.750338554382324,
      "learning_rate": 3.2986111111111115e-05,
      "loss": 0.0872,
      "step": 1030
    },
    {
      "epoch": 1.0317460317460316,
      "grad_norm": 3.121300458908081,
      "learning_rate": 3.28207671957672e-05,
      "loss": 0.0855,
      "step": 1040
    },
    {
      "epoch": 1.0416666666666667,
      "grad_norm": 0.5413240194320679,
      "learning_rate": 3.265542328042328e-05,
      "loss": 0.111,
      "step": 1050
    },
    {
      "epoch": 1.0515873015873016,
      "grad_norm": 2.6723039150238037,
      "learning_rate": 3.249007936507937e-05,
      "loss": 0.0841,
      "step": 1060
    },
    {
      "epoch": 1.0615079365079365,
      "grad_norm": 0.6056667566299438,
      "learning_rate": 3.232473544973545e-05,
      "loss": 0.0595,
      "step": 1070
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 2.3322958946228027,
      "learning_rate": 3.215939153439154e-05,
      "loss": 0.1052,
      "step": 1080
    },
    {
      "epoch": 1.0813492063492063,
      "grad_norm": 0.3279564380645752,
      "learning_rate": 3.199404761904762e-05,
      "loss": 0.0707,
      "step": 1090
    },
    {
      "epoch": 1.0912698412698412,
      "grad_norm": 0.15563958883285522,
      "learning_rate": 3.182870370370371e-05,
      "loss": 0.06,
      "step": 1100
    },
    {
      "epoch": 1.1011904761904763,
      "grad_norm": 0.06619957834482193,
      "learning_rate": 3.1663359788359795e-05,
      "loss": 0.0509,
      "step": 1110
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 1.725649118423462,
      "learning_rate": 3.1498015873015876e-05,
      "loss": 0.0648,
      "step": 1120
    },
    {
      "epoch": 1.121031746031746,
      "grad_norm": 0.0885264128446579,
      "learning_rate": 3.1332671957671964e-05,
      "loss": 0.0988,
      "step": 1130
    },
    {
      "epoch": 1.130952380952381,
      "grad_norm": 0.09525419026613235,
      "learning_rate": 3.1167328042328044e-05,
      "loss": 0.061,
      "step": 1140
    },
    {
      "epoch": 1.1408730158730158,
      "grad_norm": 0.20316679775714874,
      "learning_rate": 3.100198412698413e-05,
      "loss": 0.0406,
      "step": 1150
    },
    {
      "epoch": 1.1507936507936507,
      "grad_norm": 0.5155660510063171,
      "learning_rate": 3.083664021164021e-05,
      "loss": 0.0883,
      "step": 1160
    },
    {
      "epoch": 1.1607142857142858,
      "grad_norm": 0.11247237026691437,
      "learning_rate": 3.06712962962963e-05,
      "loss": 0.0492,
      "step": 1170
    },
    {
      "epoch": 1.1706349206349207,
      "grad_norm": 1.7112199068069458,
      "learning_rate": 3.0505952380952385e-05,
      "loss": 0.0825,
      "step": 1180
    },
    {
      "epoch": 1.1805555555555556,
      "grad_norm": 0.05518156662583351,
      "learning_rate": 3.0340608465608465e-05,
      "loss": 0.0756,
      "step": 1190
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.045167069882154465,
      "learning_rate": 3.0175264550264553e-05,
      "loss": 0.0649,
      "step": 1200
    },
    {
      "epoch": 1.2003968253968254,
      "grad_norm": 6.698178291320801,
      "learning_rate": 3.0009920634920634e-05,
      "loss": 0.0996,
      "step": 1210
    },
    {
      "epoch": 1.2103174603174602,
      "grad_norm": 0.3445168733596802,
      "learning_rate": 2.984457671957672e-05,
      "loss": 0.0204,
      "step": 1220
    },
    {
      "epoch": 1.2202380952380953,
      "grad_norm": 4.044685363769531,
      "learning_rate": 2.9679232804232802e-05,
      "loss": 0.1113,
      "step": 1230
    },
    {
      "epoch": 1.2301587301587302,
      "grad_norm": 0.037860043346881866,
      "learning_rate": 2.951388888888889e-05,
      "loss": 0.0677,
      "step": 1240
    },
    {
      "epoch": 1.2400793650793651,
      "grad_norm": 9.59068489074707,
      "learning_rate": 2.9348544973544974e-05,
      "loss": 0.1517,
      "step": 1250
    },
    {
      "epoch": 1.25,
      "grad_norm": 5.525794506072998,
      "learning_rate": 2.9183201058201058e-05,
      "loss": 0.0847,
      "step": 1260
    },
    {
      "epoch": 1.2599206349206349,
      "grad_norm": 2.886760711669922,
      "learning_rate": 2.9017857142857146e-05,
      "loss": 0.077,
      "step": 1270
    },
    {
      "epoch": 1.2698412698412698,
      "grad_norm": 0.06335362792015076,
      "learning_rate": 2.8852513227513227e-05,
      "loss": 0.0531,
      "step": 1280
    },
    {
      "epoch": 1.2797619047619047,
      "grad_norm": 0.15907207131385803,
      "learning_rate": 2.8687169312169314e-05,
      "loss": 0.0919,
      "step": 1290
    },
    {
      "epoch": 1.2896825396825398,
      "grad_norm": 0.6899881362915039,
      "learning_rate": 2.8521825396825395e-05,
      "loss": 0.027,
      "step": 1300
    },
    {
      "epoch": 1.2996031746031746,
      "grad_norm": 1.6225579977035522,
      "learning_rate": 2.8356481481481483e-05,
      "loss": 0.0906,
      "step": 1310
    },
    {
      "epoch": 1.3095238095238095,
      "grad_norm": 0.10980452597141266,
      "learning_rate": 2.8191137566137567e-05,
      "loss": 0.0366,
      "step": 1320
    },
    {
      "epoch": 1.3194444444444444,
      "grad_norm": 0.08815739303827286,
      "learning_rate": 2.802579365079365e-05,
      "loss": 0.0439,
      "step": 1330
    },
    {
      "epoch": 1.3293650793650793,
      "grad_norm": 0.046432241797447205,
      "learning_rate": 2.7860449735449735e-05,
      "loss": 0.0663,
      "step": 1340
    },
    {
      "epoch": 1.3392857142857144,
      "grad_norm": 5.183873176574707,
      "learning_rate": 2.769510582010582e-05,
      "loss": 0.1175,
      "step": 1350
    },
    {
      "epoch": 1.3492063492063493,
      "grad_norm": 1.345420241355896,
      "learning_rate": 2.7529761904761907e-05,
      "loss": 0.0613,
      "step": 1360
    },
    {
      "epoch": 1.3591269841269842,
      "grad_norm": 0.09100791066884995,
      "learning_rate": 2.736441798941799e-05,
      "loss": 0.0532,
      "step": 1370
    },
    {
      "epoch": 1.369047619047619,
      "grad_norm": 0.0635804533958435,
      "learning_rate": 2.7199074074074076e-05,
      "loss": 0.0584,
      "step": 1380
    },
    {
      "epoch": 1.378968253968254,
      "grad_norm": 0.9684438705444336,
      "learning_rate": 2.703373015873016e-05,
      "loss": 0.1432,
      "step": 1390
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 0.5663745999336243,
      "learning_rate": 2.6868386243386244e-05,
      "loss": 0.0679,
      "step": 1400
    },
    {
      "epoch": 1.3988095238095237,
      "grad_norm": 0.3949184715747833,
      "learning_rate": 2.6703042328042328e-05,
      "loss": 0.0278,
      "step": 1410
    },
    {
      "epoch": 1.4087301587301586,
      "grad_norm": 0.20060431957244873,
      "learning_rate": 2.6537698412698416e-05,
      "loss": 0.0327,
      "step": 1420
    },
    {
      "epoch": 1.4186507936507937,
      "grad_norm": 3.2071316242218018,
      "learning_rate": 2.63723544973545e-05,
      "loss": 0.0449,
      "step": 1430
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 6.68994140625,
      "learning_rate": 2.6207010582010584e-05,
      "loss": 0.1049,
      "step": 1440
    },
    {
      "epoch": 1.4384920634920635,
      "grad_norm": 0.0878763273358345,
      "learning_rate": 2.604166666666667e-05,
      "loss": 0.0793,
      "step": 1450
    },
    {
      "epoch": 1.4484126984126984,
      "grad_norm": 3.722641706466675,
      "learning_rate": 2.5876322751322753e-05,
      "loss": 0.1205,
      "step": 1460
    },
    {
      "epoch": 1.4583333333333333,
      "grad_norm": 0.2635596990585327,
      "learning_rate": 2.5710978835978837e-05,
      "loss": 0.0651,
      "step": 1470
    },
    {
      "epoch": 1.4682539682539684,
      "grad_norm": 0.04513042792677879,
      "learning_rate": 2.554563492063492e-05,
      "loss": 0.0172,
      "step": 1480
    },
    {
      "epoch": 1.4781746031746033,
      "grad_norm": 0.21350228786468506,
      "learning_rate": 2.538029100529101e-05,
      "loss": 0.0871,
      "step": 1490
    },
    {
      "epoch": 1.4880952380952381,
      "grad_norm": 6.689230918884277,
      "learning_rate": 2.521494708994709e-05,
      "loss": 0.09,
      "step": 1500
    }
  ],
  "logging_steps": 10,
  "max_steps": 3024,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.8592211414579282e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
