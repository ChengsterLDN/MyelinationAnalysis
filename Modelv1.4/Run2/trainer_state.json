{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3027,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.049554013875123884,
      "grad_norm": 2.492465019226074,
      "learning_rate": 4.919061777337298e-05,
      "loss": 0.3704,
      "step": 50
    },
    {
      "epoch": 0.09910802775024777,
      "grad_norm": 2.290940761566162,
      "learning_rate": 4.8364717542120915e-05,
      "loss": 0.2679,
      "step": 100
    },
    {
      "epoch": 0.14866204162537167,
      "grad_norm": 1.136950135231018,
      "learning_rate": 4.753881731086885e-05,
      "loss": 0.2088,
      "step": 150
    },
    {
      "epoch": 0.19821605550049554,
      "grad_norm": 1.606235384941101,
      "learning_rate": 4.6712917079616785e-05,
      "loss": 0.2692,
      "step": 200
    },
    {
      "epoch": 0.24777006937561943,
      "grad_norm": 2.159173011779785,
      "learning_rate": 4.588701684836472e-05,
      "loss": 0.1736,
      "step": 250
    },
    {
      "epoch": 0.29732408325074333,
      "grad_norm": 0.9155631065368652,
      "learning_rate": 4.5061116617112655e-05,
      "loss": 0.2289,
      "step": 300
    },
    {
      "epoch": 0.3468780971258672,
      "grad_norm": 0.40270018577575684,
      "learning_rate": 4.423521638586059e-05,
      "loss": 0.1868,
      "step": 350
    },
    {
      "epoch": 0.39643211100099107,
      "grad_norm": 1.9790222644805908,
      "learning_rate": 4.3409316154608526e-05,
      "loss": 0.1896,
      "step": 400
    },
    {
      "epoch": 0.44598612487611494,
      "grad_norm": 3.7356197834014893,
      "learning_rate": 4.258341592335646e-05,
      "loss": 0.1806,
      "step": 450
    },
    {
      "epoch": 0.49554013875123887,
      "grad_norm": 1.0043805837631226,
      "learning_rate": 4.1757515692104396e-05,
      "loss": 0.18,
      "step": 500
    },
    {
      "epoch": 0.5450941526263627,
      "grad_norm": 0.7302351593971252,
      "learning_rate": 4.093161546085233e-05,
      "loss": 0.1708,
      "step": 550
    },
    {
      "epoch": 0.5946481665014867,
      "grad_norm": 1.9022923707962036,
      "learning_rate": 4.0105715229600266e-05,
      "loss": 0.162,
      "step": 600
    },
    {
      "epoch": 0.6442021803766105,
      "grad_norm": 4.109165668487549,
      "learning_rate": 3.92798149983482e-05,
      "loss": 0.1433,
      "step": 650
    },
    {
      "epoch": 0.6937561942517344,
      "grad_norm": 0.2698989510536194,
      "learning_rate": 3.845391476709614e-05,
      "loss": 0.1669,
      "step": 700
    },
    {
      "epoch": 0.7433102081268583,
      "grad_norm": 0.367783784866333,
      "learning_rate": 3.762801453584407e-05,
      "loss": 0.1459,
      "step": 750
    },
    {
      "epoch": 0.7928642220019821,
      "grad_norm": 0.8014891147613525,
      "learning_rate": 3.680211430459201e-05,
      "loss": 0.1435,
      "step": 800
    },
    {
      "epoch": 0.8424182358771061,
      "grad_norm": 4.1081767082214355,
      "learning_rate": 3.597621407333994e-05,
      "loss": 0.1167,
      "step": 850
    },
    {
      "epoch": 0.8919722497522299,
      "grad_norm": 0.04107096791267395,
      "learning_rate": 3.515031384208788e-05,
      "loss": 0.1172,
      "step": 900
    },
    {
      "epoch": 0.9415262636273538,
      "grad_norm": 2.0118861198425293,
      "learning_rate": 3.432441361083581e-05,
      "loss": 0.1164,
      "step": 950
    },
    {
      "epoch": 0.9910802775024777,
      "grad_norm": 1.0982675552368164,
      "learning_rate": 3.349851337958375e-05,
      "loss": 0.1291,
      "step": 1000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9302777777777778,
      "eval_loss": 0.2419128268957138,
      "eval_runtime": 330.9376,
      "eval_samples_per_second": 10.878,
      "eval_steps_per_second": 1.36,
      "step": 1009
    },
    {
      "epoch": 1.0406342913776017,
      "grad_norm": 1.3408242464065552,
      "learning_rate": 3.267261314833168e-05,
      "loss": 0.0875,
      "step": 1050
    },
    {
      "epoch": 1.0901883052527255,
      "grad_norm": 0.1941027045249939,
      "learning_rate": 3.184671291707962e-05,
      "loss": 0.0577,
      "step": 1100
    },
    {
      "epoch": 1.1397423191278493,
      "grad_norm": 1.085440754890442,
      "learning_rate": 3.1020812685827553e-05,
      "loss": 0.0815,
      "step": 1150
    },
    {
      "epoch": 1.1892963330029733,
      "grad_norm": 4.608692169189453,
      "learning_rate": 3.0194912454575492e-05,
      "loss": 0.0801,
      "step": 1200
    },
    {
      "epoch": 1.2388503468780971,
      "grad_norm": 0.041467174887657166,
      "learning_rate": 2.9369012223323424e-05,
      "loss": 0.0617,
      "step": 1250
    },
    {
      "epoch": 1.288404360753221,
      "grad_norm": 0.061596907675266266,
      "learning_rate": 2.854311199207136e-05,
      "loss": 0.0656,
      "step": 1300
    },
    {
      "epoch": 1.3379583746283448,
      "grad_norm": 1.721922516822815,
      "learning_rate": 2.7717211760819294e-05,
      "loss": 0.0475,
      "step": 1350
    },
    {
      "epoch": 1.3875123885034688,
      "grad_norm": 0.039725594222545624,
      "learning_rate": 2.6891311529567233e-05,
      "loss": 0.0675,
      "step": 1400
    },
    {
      "epoch": 1.4370664023785926,
      "grad_norm": 1.9912854433059692,
      "learning_rate": 2.606541129831516e-05,
      "loss": 0.0485,
      "step": 1450
    },
    {
      "epoch": 1.4866204162537167,
      "grad_norm": 6.717009544372559,
      "learning_rate": 2.52395110670631e-05,
      "loss": 0.0324,
      "step": 1500
    },
    {
      "epoch": 1.5361744301288405,
      "grad_norm": 0.05173525959253311,
      "learning_rate": 2.4413610835811035e-05,
      "loss": 0.0828,
      "step": 1550
    },
    {
      "epoch": 1.5857284440039643,
      "grad_norm": 16.757566452026367,
      "learning_rate": 2.358771060455897e-05,
      "loss": 0.041,
      "step": 1600
    },
    {
      "epoch": 1.635282457879088,
      "grad_norm": 0.07160700857639313,
      "learning_rate": 2.2761810373306905e-05,
      "loss": 0.0453,
      "step": 1650
    },
    {
      "epoch": 1.6848364717542121,
      "grad_norm": 0.3088345527648926,
      "learning_rate": 2.193591014205484e-05,
      "loss": 0.0371,
      "step": 1700
    },
    {
      "epoch": 1.734390485629336,
      "grad_norm": 0.110361248254776,
      "learning_rate": 2.1110009910802776e-05,
      "loss": 0.0528,
      "step": 1750
    },
    {
      "epoch": 1.78394449950446,
      "grad_norm": 0.06095152348279953,
      "learning_rate": 2.028410967955071e-05,
      "loss": 0.0263,
      "step": 1800
    },
    {
      "epoch": 1.8334985133795838,
      "grad_norm": 0.2618226706981659,
      "learning_rate": 1.945820944829865e-05,
      "loss": 0.0428,
      "step": 1850
    },
    {
      "epoch": 1.8830525272547076,
      "grad_norm": 0.10771763324737549,
      "learning_rate": 1.863230921704658e-05,
      "loss": 0.0355,
      "step": 1900
    },
    {
      "epoch": 1.9326065411298314,
      "grad_norm": 0.014799983240664005,
      "learning_rate": 1.7806408985794516e-05,
      "loss": 0.0147,
      "step": 1950
    },
    {
      "epoch": 1.9821605550049552,
      "grad_norm": 0.07168245315551758,
      "learning_rate": 1.698050875454245e-05,
      "loss": 0.0296,
      "step": 2000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9447222222222222,
      "eval_loss": 0.257314532995224,
      "eval_runtime": 324.4476,
      "eval_samples_per_second": 11.096,
      "eval_steps_per_second": 1.387,
      "step": 2018
    },
    {
      "epoch": 2.031714568880079,
      "grad_norm": 0.021897634491324425,
      "learning_rate": 1.6154608523290387e-05,
      "loss": 0.0198,
      "step": 2050
    },
    {
      "epoch": 2.0812685827552033,
      "grad_norm": 0.008331382647156715,
      "learning_rate": 1.5328708292038322e-05,
      "loss": 0.004,
      "step": 2100
    },
    {
      "epoch": 2.130822596630327,
      "grad_norm": 0.038439638912677765,
      "learning_rate": 1.4502808060786257e-05,
      "loss": 0.0088,
      "step": 2150
    },
    {
      "epoch": 2.180376610505451,
      "grad_norm": 0.7061691880226135,
      "learning_rate": 1.3676907829534194e-05,
      "loss": 0.012,
      "step": 2200
    },
    {
      "epoch": 2.2299306243805748,
      "grad_norm": 0.05641253665089607,
      "learning_rate": 1.2851007598282127e-05,
      "loss": 0.01,
      "step": 2250
    },
    {
      "epoch": 2.2794846382556986,
      "grad_norm": 0.013959290459752083,
      "learning_rate": 1.2025107367030064e-05,
      "loss": 0.004,
      "step": 2300
    },
    {
      "epoch": 2.329038652130823,
      "grad_norm": 0.025155920535326004,
      "learning_rate": 1.1199207135778e-05,
      "loss": 0.0028,
      "step": 2350
    },
    {
      "epoch": 2.3785926660059467,
      "grad_norm": 7.0614423751831055,
      "learning_rate": 1.0373306904525935e-05,
      "loss": 0.0114,
      "step": 2400
    },
    {
      "epoch": 2.4281466798810705,
      "grad_norm": 0.018381021916866302,
      "learning_rate": 9.54740667327387e-06,
      "loss": 0.0034,
      "step": 2450
    },
    {
      "epoch": 2.4777006937561943,
      "grad_norm": 0.014402458444237709,
      "learning_rate": 8.721506442021803e-06,
      "loss": 0.0065,
      "step": 2500
    },
    {
      "epoch": 2.527254707631318,
      "grad_norm": 0.013279491104185581,
      "learning_rate": 7.895606210769738e-06,
      "loss": 0.005,
      "step": 2550
    },
    {
      "epoch": 2.576808721506442,
      "grad_norm": 0.006617560051381588,
      "learning_rate": 7.069705979517674e-06,
      "loss": 0.0085,
      "step": 2600
    },
    {
      "epoch": 2.6263627353815657,
      "grad_norm": 0.006415828131139278,
      "learning_rate": 6.2438057482656096e-06,
      "loss": 0.0063,
      "step": 2650
    },
    {
      "epoch": 2.6759167492566895,
      "grad_norm": 0.27625522017478943,
      "learning_rate": 5.417905517013545e-06,
      "loss": 0.0037,
      "step": 2700
    },
    {
      "epoch": 2.725470763131814,
      "grad_norm": 0.011853347532451153,
      "learning_rate": 4.592005285761481e-06,
      "loss": 0.0051,
      "step": 2750
    },
    {
      "epoch": 2.7750247770069376,
      "grad_norm": 0.00877257902175188,
      "learning_rate": 3.7661050545094155e-06,
      "loss": 0.0097,
      "step": 2800
    },
    {
      "epoch": 2.8245787908820614,
      "grad_norm": 0.02299058996140957,
      "learning_rate": 2.9402048232573507e-06,
      "loss": 0.007,
      "step": 2850
    },
    {
      "epoch": 2.8741328047571852,
      "grad_norm": 0.01078165415674448,
      "learning_rate": 2.114304592005286e-06,
      "loss": 0.0023,
      "step": 2900
    },
    {
      "epoch": 2.923686818632309,
      "grad_norm": 0.007661911658942699,
      "learning_rate": 1.288404360753221e-06,
      "loss": 0.0024,
      "step": 2950
    },
    {
      "epoch": 2.9732408325074333,
      "grad_norm": 0.044651150703430176,
      "learning_rate": 4.625041295011563e-07,
      "loss": 0.0081,
      "step": 3000
    }
  ],
  "logging_steps": 50,
  "max_steps": 3027,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.751299475479134e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
